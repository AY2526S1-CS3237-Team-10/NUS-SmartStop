{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7c89f60",
   "metadata": {},
   "source": [
    "Ensure Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1210ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (0.24.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (11.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (2.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (2.32.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision pillow numpy requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e18d76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loaded custom classes: ['0_empty', '1_low', '2_medium', '3_high']\n",
      "Successfully loaded ImageNet labels.\n",
      "Loading original ImageNet MobileNetV2...\n",
      "Loading custom model from smartstop_mobilenet_v2_esp32cam.pth...\n",
      "Loading custom model from smartstop_mobilenet_v2_esp32cam_smartstopv1.pth...\n",
      "Loading custom model from smartstop_mobilenet_v2_esp32cam_smartstopv2.pth...\n",
      "Loading custom model from smartstop_mobilenet_v2_esp32cam_smartstop.pth...\n",
      "\n",
      "--- Ready! Loaded 5 models. ---\n",
      "Starting batch prediction on all images in: ./test_images/\n",
      "\n",
      "====== Predictions for ./test_images/image851.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: mousetrap (4.34%)\n",
      "  #2: switch (3.96%)\n",
      "  #3: bullet train (1.32%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (78.4%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 0_empty (36.1%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (46.5%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 1_low (52.6%)\n",
      "\n",
      "====== Predictions for ./test_images/image852.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: switch (3.04%)\n",
      "  #2: odometer (1.11%)\n",
      "  #3: digital clock (0.98%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (88.7%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (43.9%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (53.1%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 1_low (63.4%)\n",
      "\n",
      "====== Predictions for ./test_images/image853.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: bullet train (2.69%)\n",
      "  #2: bobsled (1.54%)\n",
      "  #3: toaster (1.50%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (88.1%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (47.8%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 1_low (42.4%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 2_medium (63.9%)\n",
      "\n",
      "====== Predictions for ./test_images/image854.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: airship (1.87%)\n",
      "  #2: bullet train (1.77%)\n",
      "  #3: submarine (1.64%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (88.5%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (55.4%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (43.2%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 2_medium (46.5%)\n",
      "\n",
      "====== Predictions for ./test_images/image855.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: airship (2.89%)\n",
      "  #2: switch (2.31%)\n",
      "  #3: bullet train (1.98%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (87.5%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (65.7%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (56.9%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 1_low (77.5%)\n",
      "\n",
      "====== Predictions for ./test_images/image856.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: airship (3.17%)\n",
      "  #2: bullet train (2.66%)\n",
      "  #3: submarine (1.69%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (98.1%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (54.1%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (67.9%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 0_empty (67.0%)\n",
      "\n",
      "====== Predictions for ./test_images/image857.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: airship (1.64%)\n",
      "  #2: submarine (1.30%)\n",
      "  #3: envelope (1.29%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (97.3%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 0_empty (53.8%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (84.9%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 0_empty (95.0%)\n",
      "\n",
      "====== Predictions for ./test_images/image858.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: syringe (2.24%)\n",
      "  #2: paintbrush (1.21%)\n",
      "  #3: mousetrap (1.12%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (54.1%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 0_empty (50.4%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (50.1%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 0_empty (56.5%)\n",
      "\n",
      "====== Predictions for ./test_images/image859.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: airship (3.22%)\n",
      "  #2: pool table (1.62%)\n",
      "  #3: bullet train (0.96%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (95.7%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (58.2%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (69.1%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 2_medium (58.3%)\n",
      "\n",
      "====== Predictions for ./test_images/image860.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: airship (2.06%)\n",
      "  #2: warplane (1.11%)\n",
      "  #3: pool table (0.84%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (93.2%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (61.1%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (79.9%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 1_low (58.2%)\n",
      "\n",
      "====== Predictions for ./test_images/image861.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: rubber eraser (1.19%)\n",
      "  #2: ice lolly (1.15%)\n",
      "  #3: digital clock (1.07%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (93.9%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (70.0%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (46.5%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 2_medium (47.4%)\n",
      "\n",
      "====== Predictions for ./test_images/image862.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: pool table (3.73%)\n",
      "  #2: medicine chest (1.60%)\n",
      "  #3: ping-pong ball (1.57%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (76.5%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (59.9%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (44.0%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 2_medium (92.4%)\n",
      "\n",
      "====== Predictions for ./test_images/image863.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: switch (1.11%)\n",
      "  #2: pool table (1.09%)\n",
      "  #3: medicine chest (1.08%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (76.2%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (58.6%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (46.4%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 2_medium (76.2%)\n",
      "\n",
      "====== Predictions for ./test_images/image864.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: Band Aid (3.97%)\n",
      "  #2: piggy bank (1.50%)\n",
      "  #3: seat belt (1.48%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 3_high (61.6%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (40.0%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (44.8%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 2_medium (37.1%)\n",
      "\n",
      "====== Predictions for ./test_images/image865.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: Band Aid (5.69%)\n",
      "  #2: rubber eraser (3.92%)\n",
      "  #3: lighter (3.31%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (87.5%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (35.0%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 3_high (57.1%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 2_medium (62.8%)\n",
      "\n",
      "====== Predictions for ./test_images/image866.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: rubber eraser (5.95%)\n",
      "  #2: pill bottle (4.27%)\n",
      "  #3: pencil box (1.72%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (60.1%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (53.3%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 3_high (42.4%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 2_medium (49.7%)\n",
      "\n",
      "====== Predictions for ./test_images/image867.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: Band Aid (8.77%)\n",
      "  #2: pill bottle (5.35%)\n",
      "  #3: rubber eraser (4.62%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 3_high (63.9%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 3_high (66.1%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 3_high (73.7%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 3_high (66.1%)\n",
      "\n",
      "====== Predictions for ./test_images/image868.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: rubber eraser (7.34%)\n",
      "  #2: pill bottle (6.80%)\n",
      "  #3: ping-pong ball (4.54%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (69.9%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 3_high (47.0%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 3_high (56.4%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 3_high (74.9%)\n",
      "\n",
      "====== Predictions for ./test_images/image869.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: rubber eraser (6.65%)\n",
      "  #2: pill bottle (6.51%)\n",
      "  #3: ping-pong ball (4.15%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 3_high (51.9%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 3_high (60.6%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 3_high (53.9%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 3_high (75.0%)\n",
      "\n",
      "====== Predictions for ./test_images/image870.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: candle (4.37%)\n",
      "  #2: rubber eraser (3.89%)\n",
      "  #3: tray (3.26%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (73.3%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 3_high (47.6%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (63.6%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 3_high (91.3%)\n",
      "\n",
      "====== Predictions for ./test_images/image871.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: rubber eraser (5.17%)\n",
      "  #2: pill bottle (3.90%)\n",
      "  #3: candle (3.76%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (84.3%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 3_high (47.1%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 0_empty (46.4%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 3_high (91.5%)\n",
      "\n",
      "====== Predictions for ./test_images/image872.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: rubber eraser (7.35%)\n",
      "  #2: pill bottle (4.89%)\n",
      "  #3: pencil box (2.19%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (48.6%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (41.9%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 3_high (44.1%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 3_high (95.0%)\n",
      "\n",
      "====== Predictions for ./test_images/image873.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: rubber eraser (9.24%)\n",
      "  #2: pill bottle (5.47%)\n",
      "  #3: candle (4.33%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (77.7%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (60.2%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 3_high (44.9%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 3_high (91.1%)\n",
      "\n",
      "====== Predictions for ./test_images/image874.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: rubber eraser (6.93%)\n",
      "  #2: pill bottle (4.12%)\n",
      "  #3: ping-pong ball (3.36%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (76.3%)\n",
      "\n",
      "[Trained using actual SmartStop data v1 ]\n",
      "  Result: 1_low (49.3%)\n",
      "\n",
      "[Trained using actual SmartStop data v2]\n",
      "  Result: 3_high (52.5%)\n",
      "\n",
      "[Trained using actual SmartStop data new]\n",
      "  Result: 3_high (69.2%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Add all your custom .pth files here. Give them a friendly name.\n",
    "custom_models_to_load = {\n",
    "    # \"Trained Using iPhone Photos\": \"smartstop_mobilenet_v2_iphoneimages.pth\",\n",
    "    \"First Attempt ESP32-CAM\": \"smartstop_mobilenet_v2_esp32cam.pth\",\n",
    "    \"Trained using actual SmartStop data v1 \": \"smartstop_mobilenet_v2_esp32cam_smartstopv1.pth\",\n",
    "    \"Trained using actual SmartStop data v2\": \"smartstop_mobilenet_v2_esp32cam_smartstopv2.pth\",\n",
    "    \"Trained using actual SmartStop data new\": \"smartstop_mobilenet_v2_esp32cam_smartstop.pth\",\n",
    "   \n",
    "    # \"My Custom V2\": \"smartstop_v2_50epochs.pth\", # Add more here later\n",
    "}\n",
    "CLASS_NAMES_FILE = 'class_names.json'\n",
    "\n",
    "# Test specific images\n",
    "# TEST_IMAGES = [\"test1.jpg\", \"test2.jpg\", \"test3.jpg\", \"test4.jpg\", \"test5.jpg\", \"test6.jpg\", \"test7.jpg\", \"test8.jpg\", \"test9.jpg\"]  # List of test images\n",
    "\n",
    "# Test all in folder\n",
    "TEST_FOLDER = \"./test_images/\"\n",
    "# Define valid image file extensions\n",
    "ALLOWED_EXTENSIONS = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 1. RE-DEFINE YOUR TRANSFORMS ---\n",
    "# Must use the EXACT same transforms as training\n",
    "class SquarePad:\n",
    "    def __call__(self, image):\n",
    "        w, h = image.size\n",
    "        max_wh = max(w, h)\n",
    "        hp = int((max_wh - w) / 2)\n",
    "        vp = int((max_wh - h) / 2)\n",
    "        padding = (hp, vp, hp, vp)\n",
    "        return transforms.functional.pad(image, padding, 0, 'constant')\n",
    "\n",
    "inference_transform = transforms.Compose([\n",
    "    SquarePad(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# A. Load Custom Class Names\n",
    "with open(CLASS_NAMES_FILE, 'r') as f:\n",
    "    custom_classes = json.load(f)\n",
    "print(f\"Loaded custom classes: {custom_classes}\")\n",
    "\n",
    "# B. Load Original ImageNet Labels (for the base model)\n",
    "# We try to fetch them online for a readable output. Fallback to indices if offline.\n",
    "imagenet_classes = None\n",
    "try:\n",
    "    # This is a standard list of the 1000 ImageNet classes\n",
    "    import requests\n",
    "    url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "    imagenet_classes = requests.get(url).text.split('\\n')\n",
    "    print(\"Successfully loaded ImageNet labels.\")\n",
    "except:\n",
    "    print(\"Could not load ImageNet labels (offline?). Original model will show indices only.\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL LOADING HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "loaded_models = {}\n",
    "\n",
    "def load_original_model():\n",
    "    \"\"\"Loads the standard, pre-trained MobileNetV2\"\"\"\n",
    "    print(\"Loading original ImageNet MobileNetV2...\")\n",
    "    model = models.mobilenet_v2(weights='DEFAULT')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_custom_model(pth_path, num_classes):\n",
    "    \"\"\"Loads a fine-tuned model with your custom head\"\"\"\n",
    "    if not os.path.exists(pth_path):\n",
    "        print(f\" [WARN] Model file not found: {pth_path}\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"Loading custom model from {pth_path}...\")\n",
    "    model = models.mobilenet_v2(weights=None) # No need for defaults, we have weights\n",
    "    # Rebuild your custom head\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(model.last_channel, num_classes)\n",
    "    )\n",
    "    # Load your trained weights\n",
    "    model.load_state_dict(torch.load(pth_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 4. INITIALIZE ALL MODELS\n",
    "# ==========================================\n",
    "# 1. Load Original Base Model\n",
    "loaded_models['Original (ImageNet)'] = {\n",
    "    'model': load_original_model(),\n",
    "    'classes': imagenet_classes,\n",
    "    'type': 'imagenet'\n",
    "}\n",
    "\n",
    "# 2. Load All Custom Models\n",
    "for name, path in custom_models_to_load.items():\n",
    "    model = load_custom_model(path, len(custom_classes))\n",
    "    if model:\n",
    "        loaded_models[name] = {\n",
    "            'model': model,\n",
    "            'classes': custom_classes,\n",
    "            'type': 'custom'\n",
    "        }\n",
    "\n",
    "print(f\"\\n--- Ready! Loaded {len(loaded_models)} models. ---\")\n",
    "\n",
    "# ==========================================\n",
    "# 5. PREDICTION FUNCTION\n",
    "# ==========================================\n",
    "def predict_all(image_path):\n",
    "    # 1. Load and Preprocess Image ONCE\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        input_tensor = inference_transform(img)\n",
    "        input_batch = input_tensor.unsqueeze(0).to(device)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n====== Predictions for {image_path} ======\")\n",
    "\n",
    "    # 2. Loop through all loaded models\n",
    "    for model_name, config in loaded_models.items():\n",
    "        model = config['model']\n",
    "        classes = config['classes']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "             output = model(input_batch)\n",
    "\n",
    "        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "        \n",
    "        # --- Output Formatting ---\n",
    "        print(f\"\\n[{model_name}]\")\n",
    "        \n",
    "        if config['type'] == 'imagenet':\n",
    "            # For the original model, show Top 3 guesses because it has 1000 classes\n",
    "            top_probs, top_ids = torch.topk(probabilities, 3)\n",
    "            for i in range(3):\n",
    "                label = classes[top_ids[i]] if classes else str(top_ids[i].item())\n",
    "                print(f\"  #{i+1}: {label} ({top_probs[i].item()*100:.2f}%)\")\n",
    "                \n",
    "        else:\n",
    "            # For custom models, show the Top 1 guess\n",
    "            top_prob, top_id = torch.max(probabilities, 0)\n",
    "            label = classes[top_id.item()]\n",
    "            print(f\"  Result: {label} ({top_prob.item()*100:.1f}%)\")\n",
    "            # Optional: Show all custom class probabilities for debugging\n",
    "            # for idx, prob in enumerate(probabilities):\n",
    "            #      print(f\"  - {classes[idx]}: {prob.item()*100:.1f}%\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 6. RUN TEST BATCH\n",
    "# ==========================================\n",
    "\n",
    "# Test specific images\n",
    "# print(f\"Starting batch prediction on {len(TEST_IMAGES)} images...\")\n",
    "\n",
    "# for image_file in TEST_IMAGES:\n",
    "#     if os.path.exists(image_file):\n",
    "#         predict_all(image_file)\n",
    "#     else:\n",
    "#         print(f\"\\n [ERROR] Image not found: {image_file}\")\n",
    "\n",
    "# Test all images in folder\n",
    "if not os.path.exists(TEST_FOLDER):\n",
    "    print(f\"\\n [ERROR] Test folder not found: {TEST_FOLDER}\")\n",
    "else:\n",
    "    print(f\"Starting batch prediction on all images in: {TEST_FOLDER}\")\n",
    "    \n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(TEST_FOLDER):\n",
    "        # Check if it has a valid image extension\n",
    "        if filename.lower().endswith(ALLOWED_EXTENSIONS):\n",
    "            image_path = os.path.join(TEST_FOLDER, filename)\n",
    "            predict_all(image_path)\n",
    "        else:\n",
    "            print(f\"\\n [INFO] Skipping non-image file: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
