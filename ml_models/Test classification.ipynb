{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7c89f60",
   "metadata": {},
   "source": [
    "Ensure Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1210ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (2.8.0+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (0.23.0+cpu)\n",
      "Requirement already satisfied: pillow in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (11.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jun xu\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, requests\n",
      "\n",
      "   ---------------------------------------- 0/4 [urllib3]\n",
      "   ---------------------------------------- 0/4 [urllib3]\n",
      "   ---------------------------------------- 0/4 [urllib3]\n",
      "   ---------------------------------------- 0/4 [urllib3]\n",
      "   ---------- ----------------------------- 1/4 [idna]\n",
      "   -------------------- ------------------- 2/4 [charset_normalizer]\n",
      "   -------------------- ------------------- 2/4 [charset_normalizer]\n",
      "   ------------------------------ --------- 3/4 [requests]\n",
      "   ------------------------------ --------- 3/4 [requests]\n",
      "   ---------------------------------------- 4/4 [requests]\n",
      "\n",
      "Successfully installed charset_normalizer-3.4.4 idna-3.11 requests-2.32.5 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision pillow numpy requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e18d76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loaded custom classes: ['0_empty', '1_low', '2_medium', '3_high']\n",
      "Successfully loaded ImageNet labels.\n",
      "Loading original ImageNet MobileNetV2...\n",
      "Loading custom model from smartstop_mobilenet_v2_iphoneimages.pth...\n",
      "Loading custom model from smartstop_mobilenet_v2_esp32cam.pth...\n",
      "\n",
      "--- Ready! Loaded 3 models. ---\n",
      "Starting batch prediction on 9 images...\n",
      "\n",
      "====== Predictions for test1.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: bolo tie (3.73%)\n",
      "  #2: cleaver (2.77%)\n",
      "  #3: hook (1.82%)\n",
      "\n",
      "[Trained Using iPhone Photos]\n",
      "  Result: 0_empty (72.0%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 0_empty (63.6%)\n",
      "\n",
      "====== Predictions for test2.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: tray (3.68%)\n",
      "  #2: chest (3.65%)\n",
      "  #3: spider web (2.66%)\n",
      "\n",
      "[Trained Using iPhone Photos]\n",
      "  Result: 0_empty (94.2%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 1_low (40.8%)\n",
      "\n",
      "====== Predictions for test3.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: lampshade (2.84%)\n",
      "  #2: window shade (2.81%)\n",
      "  #3: table lamp (1.73%)\n",
      "\n",
      "[Trained Using iPhone Photos]\n",
      "  Result: 2_medium (40.8%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 0_empty (89.5%)\n",
      "\n",
      "====== Predictions for test4.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: television (3.27%)\n",
      "  #2: screen (2.55%)\n",
      "  #3: projector (2.31%)\n",
      "\n",
      "[Trained Using iPhone Photos]\n",
      "  Result: 2_medium (44.6%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 0_empty (93.4%)\n",
      "\n",
      "====== Predictions for test5.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: candle (9.95%)\n",
      "  #2: torch (2.58%)\n",
      "  #3: spotlight (2.54%)\n",
      "\n",
      "[Trained Using iPhone Photos]\n",
      "  Result: 2_medium (66.4%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 1_low (98.8%)\n",
      "\n",
      "====== Predictions for test6.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: digital clock (6.90%)\n",
      "  #2: matchstick (5.95%)\n",
      "  #3: switch (2.51%)\n",
      "\n",
      "[Trained Using iPhone Photos]\n",
      "  Result: 2_medium (59.8%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 1_low (96.1%)\n",
      "\n",
      "====== Predictions for test7.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: tray (4.08%)\n",
      "  #2: balloon (3.90%)\n",
      "  #3: lampshade (2.95%)\n",
      "\n",
      "[Trained Using iPhone Photos]\n",
      "  Result: 2_medium (47.5%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (95.9%)\n",
      "\n",
      "====== Predictions for test8.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: digital clock (7.65%)\n",
      "  #2: screen (4.23%)\n",
      "  #3: monitor (3.28%)\n",
      "\n",
      "[Trained Using iPhone Photos]\n",
      "  Result: 2_medium (64.6%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 2_medium (89.3%)\n",
      "\n",
      "====== Predictions for test9.jpg ======\n",
      "\n",
      "[Original (ImageNet)]\n",
      "  #1: digital clock (13.01%)\n",
      "  #2: monitor (2.99%)\n",
      "  #3: screen (2.50%)\n",
      "\n",
      "[Trained Using iPhone Photos]\n",
      "  Result: 2_medium (37.9%)\n",
      "\n",
      "[First Attempt ESP32-CAM]\n",
      "  Result: 3_high (99.1%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Add all your custom .pth files here. Give them a friendly name.\n",
    "custom_models_to_load = {\n",
    "    \"Trained Using iPhone Photos\": \"smartstop_mobilenet_v2_iphoneimages.pth\",\n",
    "    \"First Attempt ESP32-CAM\": \"smartstop_mobilenet_v2_esp32cam.pth\",\n",
    "    # \"My Custom V2\": \"smartstop_v2_50epochs.pth\", # Add more here later\n",
    "}\n",
    "CLASS_NAMES_FILE = 'class_names.json'\n",
    "TEST_IMAGES = [\"test1.jpg\", \"test2.jpg\", \"test3.jpg\", \"test4.jpg\", \"test5.jpg\", \"test6.jpg\", \"test7.jpg\", \"test8.jpg\", \"test9.jpg\"]  # List of test images\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 1. RE-DEFINE YOUR TRANSFORMS ---\n",
    "# Must use the EXACT same transforms as training\n",
    "class SquarePad:\n",
    "    def __call__(self, image):\n",
    "        w, h = image.size\n",
    "        max_wh = max(w, h)\n",
    "        hp = int((max_wh - w) / 2)\n",
    "        vp = int((max_wh - h) / 2)\n",
    "        padding = (hp, vp, hp, vp)\n",
    "        return transforms.functional.pad(image, padding, 0, 'constant')\n",
    "\n",
    "inference_transform = transforms.Compose([\n",
    "    SquarePad(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# A. Load Custom Class Names\n",
    "with open(CLASS_NAMES_FILE, 'r') as f:\n",
    "    custom_classes = json.load(f)\n",
    "print(f\"Loaded custom classes: {custom_classes}\")\n",
    "\n",
    "# B. Load Original ImageNet Labels (for the base model)\n",
    "# We try to fetch them online for a readable output. Fallback to indices if offline.\n",
    "imagenet_classes = None\n",
    "try:\n",
    "    # This is a standard list of the 1000 ImageNet classes\n",
    "    import requests\n",
    "    url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "    imagenet_classes = requests.get(url).text.split('\\n')\n",
    "    print(\"Successfully loaded ImageNet labels.\")\n",
    "except:\n",
    "    print(\"Could not load ImageNet labels (offline?). Original model will show indices only.\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL LOADING HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "loaded_models = {}\n",
    "\n",
    "def load_original_model():\n",
    "    \"\"\"Loads the standard, pre-trained MobileNetV2\"\"\"\n",
    "    print(\"Loading original ImageNet MobileNetV2...\")\n",
    "    model = models.mobilenet_v2(weights='DEFAULT')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_custom_model(pth_path, num_classes):\n",
    "    \"\"\"Loads a fine-tuned model with your custom head\"\"\"\n",
    "    if not os.path.exists(pth_path):\n",
    "        print(f\" [WARN] Model file not found: {pth_path}\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"Loading custom model from {pth_path}...\")\n",
    "    model = models.mobilenet_v2(weights=None) # No need for defaults, we have weights\n",
    "    # Rebuild your custom head\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(model.last_channel, num_classes)\n",
    "    )\n",
    "    # Load your trained weights\n",
    "    model.load_state_dict(torch.load(pth_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 4. INITIALIZE ALL MODELS\n",
    "# ==========================================\n",
    "# 1. Load Original Base Model\n",
    "loaded_models['Original (ImageNet)'] = {\n",
    "    'model': load_original_model(),\n",
    "    'classes': imagenet_classes,\n",
    "    'type': 'imagenet'\n",
    "}\n",
    "\n",
    "# 2. Load All Custom Models\n",
    "for name, path in custom_models_to_load.items():\n",
    "    model = load_custom_model(path, len(custom_classes))\n",
    "    if model:\n",
    "        loaded_models[name] = {\n",
    "            'model': model,\n",
    "            'classes': custom_classes,\n",
    "            'type': 'custom'\n",
    "        }\n",
    "\n",
    "print(f\"\\n--- Ready! Loaded {len(loaded_models)} models. ---\")\n",
    "\n",
    "# ==========================================\n",
    "# 5. PREDICTION FUNCTION\n",
    "# ==========================================\n",
    "def predict_all(image_path):\n",
    "    # 1. Load and Preprocess Image ONCE\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        input_tensor = inference_transform(img)\n",
    "        input_batch = input_tensor.unsqueeze(0).to(device)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n====== Predictions for {image_path} ======\")\n",
    "\n",
    "    # 2. Loop through all loaded models\n",
    "    for model_name, config in loaded_models.items():\n",
    "        model = config['model']\n",
    "        classes = config['classes']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "             output = model(input_batch)\n",
    "\n",
    "        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "        \n",
    "        # --- Output Formatting ---\n",
    "        print(f\"\\n[{model_name}]\")\n",
    "        \n",
    "        if config['type'] == 'imagenet':\n",
    "            # For the original model, show Top 3 guesses because it has 1000 classes\n",
    "            top_probs, top_ids = torch.topk(probabilities, 3)\n",
    "            for i in range(3):\n",
    "                label = classes[top_ids[i]] if classes else str(top_ids[i].item())\n",
    "                print(f\"  #{i+1}: {label} ({top_probs[i].item()*100:.2f}%)\")\n",
    "                \n",
    "        else:\n",
    "            # For custom models, show the Top 1 guess\n",
    "            top_prob, top_id = torch.max(probabilities, 0)\n",
    "            label = classes[top_id.item()]\n",
    "            print(f\"  Result: {label} ({top_prob.item()*100:.1f}%)\")\n",
    "            # Optional: Show all custom class probabilities for debugging\n",
    "            # for idx, prob in enumerate(probabilities):\n",
    "            #      print(f\"  - {classes[idx]}: {prob.item()*100:.1f}%\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 6. RUN TEST BATCH\n",
    "# ==========================================\n",
    "print(f\"Starting batch prediction on {len(TEST_IMAGES)} images...\")\n",
    "\n",
    "for image_file in TEST_IMAGES:\n",
    "    if os.path.exists(image_file):\n",
    "        predict_all(image_file)\n",
    "    else:\n",
    "        print(f\"\\n [ERROR] Image not found: {image_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
